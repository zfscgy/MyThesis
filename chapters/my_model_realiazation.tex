\chapter{模型测试与评估}
本文需要进行三组实验，分别是
\begin{enumerate}
    \item 对是否违约的标签的预测：用第\ref{data_refinement}章处理之后的数据，将其跟之前的研究\cite{czh}处理的数据，使用三种模型进行预测，对比显示出通过更加细致的数据处理工作产生的数据对模型预测效果的提高。
    \item 对缺失值填补算法的效果评估和对比：使用第\ref{data_refinement}章处理后的数据，将第\ref{data_imputation}章提出的基于嵌入的缺失值填补方法和广泛采用的AutoEncoder进行对比。
    \item 缺失值填补对预测效果的影响：把缺失值填补之后的数据和填补之前的数据，用三种模型分别进行预测，判断缺失值填补对于模型预测效果的影响。
\end{enumerate}
\section{对是否违约标签的预测}
\subsection{数据设置}
我们从前期整理的风控数据集里取出100000条用户信息，然后使用5折交叉验证方法，每次用80000条用户信息作为训练集，用20000条用户信息作为测试集。

对预测数据的评估方法采用准确率和AUC分数。准确率用0.5作为分界线。

对于无法处理缺失值的模型，比如神经网络，采用缺失值补0的方法进行预测。
\subsection{模型设置}
由于线性模型的拟合能力显然低于逻辑回归，而支持向量机对此类型大数据的训练相当缓慢。而随机森林的效率和准确度被认为是不如其改进版XGBoost的。因此在这里我们仅采用逻辑回归、神经网络以及XGBoost三种模型进行测试。

对于逻辑回归，我们把其当作单层神经网络，和神经网络一起使用Tensorflow框架\footnote{tensorflow.org}进行训练。XGBoost模型则使用python的xgboost库\footnote{xgboost.org}。
\begin{itemize}
    \item 逻辑回归：学习率0.1，使用梯度下降优化器。损失函数为均方误差。
    \item 神经网络：隐层神经元数目为100，学习率0.002，使用Adam优化器，激活函数全部使用sigmoid。损失函数为均方误差。
    \item XGBoost：树深度为5，学习率(eta)0.3，目标：二分类逻辑回归，列采样率0.6。
\end{itemize}
模型中若有为声明的其他参数，均按照库函数的缺省值为准。我们对所有模型都进行5折交叉验证，迭代40次。然后分别以AUC Score和准确率进行评判。
\subsection{实验结果}
\begin{table}[htp]
    \centering\small
    \caption{模型效果对照表}
    \begin{tabular}{lllllllll}
    \toprule
     & AUC-Score              &              &              &  & Accuracy              &              &             &  \\
    \midrule
    epoch & LR              & DNN             & XGB             &  & LR              & DNN             & XGB             &  \\
    ... & ...             & ...             & ...             &     & ...             & ...             & ...             &  \\
    10  & 0.8147          & 0.8419          & 0.8599          &     & 0.7782          & 0.7949          & 0.7963          &  \\
    11  & 0.8152          & 0.8429          & 0.8614          &     & 0.7794          & 0.7942          & 0.7978          &  \\
    12  & 0.8154          & 0.8434          & 0.8626          &     & 0.7786          & 0.7924          & 0.7993          &  \\
    13  & 0.8153          & 0.8442          & 0.8637          &     & 0.7794          & 0.7934          & 0.8001          &  \\
    14  & 0.8158          & \textbf{0.8459} & 0.8648          &     & 0.7797          & \textbf{0.7981} & 0.8009          &  \\
    15  & 0.8160          & 0.8444          & 0.8657          &     & 0.7792          & 0.7941          & 0.8015          &  \\
    ... & ...             & ...             & ...             &     & ...             & ...             & ...             &  \\
    30  & 0.8177          & 0.8315          & 0.8767          &     & 0.7802          & 0.7867          & 0.8111          &  \\
    31  & 0.8175          & 0.8338          & 0.8771          &     & \textbf{0.7815} & 0.7880          & 0.8113          &  \\
    32  & 0.8178          & 0.8309          & 0.8776          &     & 0.7809          & 0.7867          & 0.8120          &  \\
    ... & ...             & ...             & ...             &     & ...             & ...             & ...             &  \\   
    37  & 0.8174          & 0.8280          & 0.8797          &     & 0.7807          & 0.7854          & 0.8147          &  \\
    38  & \textbf{0.8185} & 0.8275          & 0.8800          &     & 0.7782          & 0.7855          & 0.8155          &  \\
    39  & 0.8183          & 0.8238          & \textbf{0.8805} &     & 0.7804          & 0.7807          & \textbf{0.8157} &  \\
    \bottomrule
    \end{tabular}
\end{table}
可见在LR、DNN、Xgboost三种模型中，Xgboost的表现要明显优于前两者。通过与同一数据集之前的测试结果\cite{czh}进行比较，可以看出，通过第 \ref{data_refinement} 章中采用的数据处理方法得到的数据，在使用同样的模型预测时，效果要显著好于之前的结果。

\begin{table}[htb]
\centering\small
\caption{前后结果对照}
    \begin{tabular}{ccc}
        \toprule
        模型-指标  & 之前的数据 & 本文处理的数据 \\
        \midrule
        LR-AUC  & 0.770  & 0.8185 \\
        DNN-AUC & 0.779  & 0.8469 \\
        XGB-AUC & 0.785  & 0.8805 \\
        LR-ACC & 0.711  & 0.7815 \\
        DNN-ACC & 0.717  & 0.7981 \\
        XGB-ACC & 0.721  & 0.8157 \\
        \bottomrule
    \end{tabular}
\end{table}

实验结果证明了对数据的预处理在很大程度上能够影响模型的预测效果。之前的数据处理基本上只是提取出了数值数据，没有考察很多字符串类型的类别数据，同时把很多“非数值”类型的“伪数值”数据也当作数值传入（比如手机号码的各种数据），增大了样本的噪声。而本文实行的数据处理人工考察了数据，并且对列表类型的数据丢弃了最大最小值，加入了列表总长。


\section{对缺失值填补算法的效果评估和对比}
\subsection{数据设置}
我们使用第\ref{data_refinement}章中处理好的风控数据来产生新的三元组数据集。

因为原数据集含有100,000个样本，每个样本有1156个特征，因此总共可以转化成115,600,000条三元组数据。其中缺失的数据总共有17,045,944个，缺失率为14.7\%。

因为三元组数据的数据量非常巨大，因此只需要用一小部分作为测试集就可以测出较为准确的效果。我们把所有三元组数据中的0.03\%作为测试集，测试集含有30000多条三元组数据。

\subsection{模型设置}
\begin{itemize}
    \item AutoEncoder:  使用单层的AutoEncoder，神经元数量为256，激活函数为sigmoid，训练Batch大小为100。
    \item 特征嵌入模型：样本和特征的嵌入向量维度都是128。对于嵌入向量加入规范化项，权重为0.1。内部神经网络的隐层神经元数为64，隐层激活函数为relu，输出层激活函数为sigmoid。
\end{itemize}

所有模型均采用学习率为0.02的Adam Optimzer执行梯度下降算法。损失函数使用均方误差。
\subsection{实验结果}
\begin{table}[htb]
    \caption{模型效果对照表}
    \centering
    \begin{tabular}{lll}
    \toprule
    Epochs & AutoEncoder & 特征嵌入模型 \\
    \midrule
    1 & 0.00845 & 0.00479 \\
    2 & \textbf{0.00834} & 0.00401 \\
    ... & ... & ... \\
    6 & 0.01451 & 0.00327 \\
    7 & 0.01555 & \textbf{0.00319} \\
    8 & 0.01680 & 0.00336 \\
    \bottomrule
    \end{tabular}
\end{table}
相比于AutoEncoder，使用特征嵌入模型的缺失值填补要更为精准，在数次迭代之后，AutoEncoder出现了过拟合现象，但是特征嵌入模型保持着较低的损失。

\section{缺失值填补对预测效果的影响}
由于我们使用的原始数据集是多个数据集进行内联得到的，所以数据的稀疏性并不是很大，缺失比率不到15\%，所以在多次实验中发现使用缺失值填补算法并不能对预测效果有改善，甚至因为引入了新的噪声会使预测效果出现微小的下降。

但是如果把数据集中的一半非缺失数据丢弃，使得数据缺失比率达到60\%，则LR回归和神经网络的预测效果会因为缺失值的填补而得到提升，但是Xgboost的预测效果依然出现了下降。
\subsection{数据设置}
实验数据集分为未填补缺失值的原始数据集和经过缺失值填补的数据集。对于每一数据集都采用5折交叉验证，最多进行40轮迭代，并且从其中选出平均分数最高的一轮，进行对比。
\subsection{模型设置}
缺失值填补模型采用上述的特征嵌入模型，参数与上述实验中的模型参数相同，回归模型则采用第一节中各个用于原始数据回归的LR、DNN、Xgb模型，参数亦保持不变。
\subsection{实验结果}
\begin{table}[htb]
    \caption{模型效果对照表}
    \centering
    \begin{tabular}{lll}
    \toprule
    模型-指标 & 缺失值未填补 & 缺失值填补 \\
    \midrule
    LR-auc & 0.7454 & 0.7591 \\
    LR-acc & 0.7545 & 0.7580 \\
    DNN-auc & 0.7590 & 0.7648 \\
    DNN-acc & 0.7590 & 0.7600 \\
    Xgb-auc & 0.8275 & 0.8201 \\
    Xgb-acc & 0.7776 & 0.7730 \\
    \bottomrule
    \end{tabular}
\end{table}

可见Xgboost在缺失值未填补的情况下效果最好。我们猜测这是因为Xgboost自身可以动态选择把缺失值划归哪一颗子树，因此能够较好地处理缺失值。而神经网络等算法自身并不能处理缺失数据，必须用一个值进行代替（比如是0或平均值，本实验中用的是0），因此缺失率过高时，会学习到“错误信息”，因此填补缺失值能够提高预测效果。